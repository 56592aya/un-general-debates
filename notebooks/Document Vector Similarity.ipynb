{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Vector Exploration\n",
    "\n",
    "The VDSH model learns latent vector representations of documents. These are then used to hash documents, but the vectors by themselves are still very useful for similarity search. This is also a good sanity check that the network is learning.\n",
    "\n",
    "In this notebook, I pass each document through the trained encoder to get the latent vector representations, and then I use [FAISS](https://github.com/facebookresearch/faiss) for similarity search. FAISS lets us query for nearest neighbors among the nearly 300k documents near instantaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from gensim.corpora import Dictionary\n",
    "from src.utils.corpus import Corpus\n",
    "from src.utils.tfidf import generate_tfidf\n",
    "from src.models.vdsh import VDSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()\n",
    "dictionary = Dictionary(corpus.debates.bag_of_words)\n",
    "dictionary.filter_extremes(no_below=100)\n",
    "dictionary.compactify()\n",
    "X = generate_tfidf(corpus.debates, dictionary)\n",
    "vdsh = VDSH()\n",
    "vdsh.build_model(X.shape[1])\n",
    "vdsh.load_weights('vdsh.hdf5')\n",
    "latent_vectors = vdsh.encoder_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(latent_vectors.shape[1])\n",
    "index.add(latent_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 283322\n",
    "k = 10\n",
    "D, I = index.search(latent_vectors[target].reshape((1,-1)), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_paragraph(i):\n",
    "    doc = corpus.iloc[i]\n",
    "    print(doc.country_name, doc.year)\n",
    "    print(doc.text)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_paragraph(target)\n",
    "print('Nearest Neighbors:\\n')\n",
    "for i in I[0]:\n",
    "    if i == target:\n",
    "        continue\n",
    "    print_paragraph(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "un-general-debates",
   "language": "python",
   "name": "un-general-debates"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
